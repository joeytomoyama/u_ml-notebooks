{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 6 - Text Classification Pipeline\n",
    "\n",
    "In this task you will apply the concepts learned in the last sessions:\n",
    "\n",
    "- Feature Extraction for Text data\n",
    "- scikit-learn pipelines\n",
    "- ML Model Evaluation\n",
    "- Cross-Validation\n",
    "\n",
    "As all these things are too complex to implement in an exercise, we will be using existing libraries for this, in particular ``scikit-learn``. \n",
    "\n",
    "We also will make use of a library for storing tabular data, ``pandas``, our data will be stored as pandas dataframe. You don't need to understand much about this format, except for how to retrieve a column from it. Just like for dictionaries you can type ``df[colname]`` to get the column values. \n",
    "\n",
    "The first cell downloads some text data, it's a number of speeches in the German Parliament, the *Bundestag*. \n",
    "\n",
    "Your task will be to predict party affiliation from the speech text. \n",
    "\n",
    "You will do that by building a sklearn pipeline and use grid search to optimize the n-gram range of thee text featurizer. \n",
    "\n",
    "You can check whether your code worked if it produces the same classification reports as the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "\n",
    "import os, gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATADIR = \"data\"\n",
    "\n",
    "if not os.path.exists(DATADIR): \n",
    "    os.mkdir(DATADIR)\n",
    "\n",
    "file_name = os.path.join(DATADIR, 'bundestags_parlamentsprotokolle.csv.gzip')\n",
    "if not os.path.exists(file_name):\n",
    "    url_data = 'https://www.dropbox.com/s/1nlbfehnrwwa2zj/bundestags_parlamentsprotokolle.csv.gzip?dl=1'\n",
    "    urllib.request.urlretrieve(url_data, file_name)\n",
    "\n",
    "df = pd.read_csv(gzip.open(file_name), index_col=0).sample(n=10000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the first 4 rows of the pandas dataframe like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sitzung</th>\n",
       "      <th>wahlperiode</th>\n",
       "      <th>sprecher</th>\n",
       "      <th>text</th>\n",
       "      <th>partei</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17908</th>\n",
       "      <td>201</td>\n",
       "      <td>17</td>\n",
       "      <td>Ulrich Lange</td>\n",
       "      <td>Es ist vielmehr – das erlaube ich mir hier sch...</td>\n",
       "      <td>cducsu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42100</th>\n",
       "      <td>226</td>\n",
       "      <td>18</td>\n",
       "      <td>Doris Wagner</td>\n",
       "      <td>Ein weiteres Finanzierungsinstrument, um diese...</td>\n",
       "      <td>gruene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18777</th>\n",
       "      <td>209</td>\n",
       "      <td>17</td>\n",
       "      <td>Heidrun Bluhm</td>\n",
       "      <td>In den letzten zwei Jahrzehnten sind immer meh...</td>\n",
       "      <td>linke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14589</th>\n",
       "      <td>168</td>\n",
       "      <td>17</td>\n",
       "      <td>Dr. Egon Jüttner</td>\n",
       "      <td>– Ja. – Von rund 80 000 bis 100 000 Herero im ...</td>\n",
       "      <td>cducsu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sitzung  wahlperiode          sprecher   \n",
       "17908      201           17      Ulrich Lange  \\\n",
       "42100      226           18      Doris Wagner   \n",
       "18777      209           17     Heidrun Bluhm   \n",
       "14589      168           17  Dr. Egon Jüttner   \n",
       "\n",
       "                                                    text  partei  \n",
       "17908  Es ist vielmehr – das erlaube ich mir hier sch...  cducsu  \n",
       "42100  Ein weiteres Finanzierungsinstrument, um diese...  gruene  \n",
       "18777  In den letzten zwei Jahrzehnten sind immer meh...   linke  \n",
       "14589  – Ja. – Von rund 80 000 bis 100 000 Herero im ...  cducsu  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:4]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your solution will have to implement the following parts:\n",
    "\n",
    "- Split the data into train (80%) and test (20%) set. You can use the sklearn function ``train_test_split`` for this.\n",
    "\n",
    "- Build a pipeline with a [``TfidfVectorizer``](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) and a [``NearestCentroid``](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestCentroid.html) classifier\n",
    "\n",
    "- Train the pipeline inside a [``GridSearchCV``](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) object on the training data. Try to find the best ``n_gram_range`` for the Vectorizer.\n",
    "\n",
    "- Evaluate F1, precision, recall on the test data. You can use the sklearn function ``classification_report`` for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/joey/Studium/5semester/ml/repos/venv/lib/python3.10/site-packages (1.24.3)\n",
      "Requirement already satisfied: matplotlib in /home/joey/Studium/5semester/ml/repos/venv/lib/python3.10/site-packages (3.7.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/joey/Studium/5semester/ml/repos/venv/lib/python3.10/site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/joey/Studium/5semester/ml/repos/venv/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/joey/Studium/5semester/ml/repos/venv/lib/python3.10/site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/joey/Studium/5semester/ml/repos/venv/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/joey/Studium/5semester/ml/repos/venv/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/joey/Studium/5semester/ml/repos/venv/lib/python3.10/site-packages (from matplotlib) (4.39.4)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/joey/Studium/5semester/ml/repos/venv/lib/python3.10/site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/joey/Studium/5semester/ml/repos/venv/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/joey/Studium/5semester/ml/repos/venv/lib/python3.10/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/joey/Studium/5semester/ml/repos/venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in /home/joey/Studium/5semester/ml/repos/venv/lib/python3.10/site-packages (1.2.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/joey/Studium/5semester/ml/repos/venv/lib/python3.10/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/joey/Studium/5semester/ml/repos/venv/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/joey/Studium/5semester/ml/repos/venv/lib/python3.10/site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/joey/Studium/5semester/ml/repos/venv/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "# uncomment these lines to install the required dependencies.\n",
    "# !pip install numpy\n",
    "# !pip install matplotlib\n",
    "# !pip install scikit-learn\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parties = df[\"partei\"].values\n",
    "statements = df[\"text\"].values\n",
    "\n",
    "\n",
    "train_data, test_data, train_labels , test_lables = train_test_split(statements, parties, test_size=0.2, shuffle=True)\n",
    "\n",
    "ngram_ranges = {\"tfidfvectorizer__ngram_range\": [(1,1),(1,2),(1,3),(2,2),(2,3),(3,3)]}\n",
    "\n",
    "clf = GridSearchCV(make_pipeline(TfidfVectorizer(), NearestCentroid()), ngram_ranges, n_jobs=-1)\n",
    "clf.fit(train_data, train_labels)\n",
    "\n",
    "clf = clf.best_estimator_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparision with Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      cducsu       0.97      0.97      0.97      2911\n",
      "         fdp       1.00      1.00      1.00       610\n",
      "      gruene       0.98      0.96      0.97      1256\n",
      "       linke       0.99      0.94      0.96      1119\n",
      "         spd       0.96      0.99      0.97      2104\n",
      "\n",
      "    accuracy                           0.97      8000\n",
      "   macro avg       0.98      0.97      0.97      8000\n",
      "weighted avg       0.97      0.97      0.97      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ncc_predictions = clf.predict(train_data)\n",
    "print(classification_report(ncc_predictions, train_labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparision with Testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      cducsu       0.74      0.55      0.63       971\n",
      "         fdp       0.08      0.42      0.13        31\n",
      "      gruene       0.28      0.32      0.30       240\n",
      "       linke       0.42      0.57      0.48       202\n",
      "         spd       0.42      0.42      0.42       556\n",
      "\n",
      "    accuracy                           0.48      2000\n",
      "   macro avg       0.38      0.46      0.39      2000\n",
      "weighted avg       0.55      0.48      0.51      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ncc_predictions_test = clf.predict(test_data)\n",
    "print(classification_report(ncc_predictions_test, test_lables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer(ngram_range=(2, 2))),\n",
      "                ('nearestcentroid', NearestCentroid())])\n"
     ]
    }
   ],
   "source": [
    "print(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
